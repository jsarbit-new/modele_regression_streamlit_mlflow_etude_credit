import streamlit as st
import pandas as pd
import numpy as np
import mlflow
import json
import logging
import os
import streamlit.components.v1 as components
import shap
from evidently.dashboard import Dashboard
from evidently.tabs import DataDriftTab
from sklearn.model_selection import train_test_split

# --- 1. Page Configuration Streamlit ---
st.set_page_config(
    page_title="Pr√©diction de D√©faut Client & Surveillance",
    page_icon="üìä",
    layout="wide"
)

# --- 2. Logging Configuration ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- 3. MLflow Model Path Configuration ---
# IMPORTANT: Ce chemin doit pointer vers le dossier 'modele_mlflow'
# que vous avez copi√© de votre dossier mlruns/X/run_id/artifacts/model
# et plac√© √† la racine de votre d√©p√¥t GitHub.
LOCAL_MODEL_PATH = "modele_mlflow"

# --- 4. Feature Engineering Functions (Stubs) ---
# Dictionnaire des variables importantes √† afficher dans l'interface
SHAP_IMPORTANT_FEATURES_INFO = {
    "AMT_CREDIT": {"display_name": "Montant du Pr√™t", "min_val": 50000.0, "max_val": 2000000.0},
    "AMT_ANNUITY": {"display_name": "Montant Annuit√©", "min_val": 1000.0, "max_val": 100000.0},
    "app_feature_15": {"display_name": "Ratio Cr√©dit/Annuit√©", "min_val": 0.01, "max_val": 10.0},
    "app_feature_33": {"display_name": "Anciennet√© Emploi (ann√©es)", "min_val": 0.0, "max_val": 50.0},
    "app_feature_21": {"display_name": "Taux Population R√©gion", "min_val": 0.001, "max_val": 0.1},
    "app_feature_19": {"display_name": "Source Ext√©rieure 1", "min_val": 0.0, "max_val": 1.0},
    "app_feature_31": {"display_name": "Source Ext√©rieure 2", "min_val": 0.0, "max_val": 1.0},
    "app_feature_24": {"display_name": "Source Ext√©rieure 3", "min_val": 0.0, "max_val": 1.0},
    "app_feature_45": {"display_name": "Nombre Enfants", "min_val": 0.0, "max_val": 10.0},
    "app_feature_17": {"display_name": "Age Client (ann√©es)", "min_val": 18.0, "max_val": 70.0},
}
# SHAP_IMPORTANT_FEATURES_NAMES = list(SHAP_IMPORTANT_FEATURES_INFO.keys()) # Cette ligne est redondante

# NOUVEAU: Dictionnaire de noms descriptifs pour TOUTES les variables
FULL_DESCRIPTIVE_NAMES = {
    # Variables ajout√©es dans l'interface
    "AMT_CREDIT": "Montant du Pr√™t",
    "AMT_ANNUITY": "Montant Annuit√©",
    
    # Variables de la famille 'app_feature'
    "app_feature_15": "Ratio Cr√©dit/Annuit√©",
    "app_feature_33": "Anciennet√© Emploi (ann√©es)",
    "app_feature_21": "Taux Population R√©gion",
    "app_feature_19": "Source Ext√©rieure 1",
    "app_feature_31": "Source Ext√©rieure 2",
    "app_feature_24": "Source Ext√©rieure 3",
    "app_feature_45": "Nombre Enfants",
    "app_feature_17": "Age Client (ann√©es)",
    "app_feature_0": "Statut de la demande",
    "app_feature_1": "Statut de propri√©t√©",
    "app_feature_2": "Montant du bien",
    "app_feature_3": "Type de logement",
    "app_feature_4": "Type de famille",
    "app_feature_5": "Nb de jours depuis l'enregistrement",
    "app_feature_6": "Score 1 du client",
    "app_feature_7": "Score 2 du client",
    "app_feature_8": "Score 3 du client",
    "app_feature_9": "Nb d'enqu√™tes r√©centes",
    "app_feature_10": "Dernier changement d'ID",
    "app_feature_11": "Dernier changement de document",
    "app_feature_12": "Score financier 1",
    "app_feature_13": "Score financier 2",
    "app_feature_14": "Score financier 3",
    "app_feature_18": "Ratio Annuit√©/Revenu",
    "app_feature_20": "Type de paiement",
    "app_feature_22": "Score de cr√©dit Bureau",
    "app_feature_23": "Nb de paiements manqu√©s",
    "app_feature_25": "Ratio dette/revenu",
    "app_feature_26": "Nb de cr√©dits en cours",
    "app_feature_27": "Nb de demandes par t√©l√©phone",
    "app_feature_28": "Nb de cr√©dits renouvelables",
    "app_feature_29": "Nb de cr√©dits sold√©s",
    "app_feature_30": "Montant de l'assurance",
    "app_feature_32": "Nb de jours depuis le dernier cr√©dit",
    "app_feature_34": "Dernier changement de contact",
    "app_feature_35": "Derni√®re mise √† jour d'info",
    "app_feature_36": "Montant des p√©nalit√©s",
    "app_feature_37": "Montant des arri√©r√©s",
    "app_feature_38": "Nb de jours depuis le dernier contact",
    "app_feature_39": "Montant des paiements r√©guliers",
    "app_feature_40": "Ratio paiements/solde",
    "app_feature_41": "Nb de jours depuis le dernier paiement",
    "app_feature_42": "Dernier montant rembours√©",
    "app_feature_43": "Nb de jours depuis le d√©but du pr√™t",
    "app_feature_44": "Nb de paiements totaux",
    "app_feature_46": "Nb de paiements manqu√©s totaux",
    "app_feature_47": "Montant total de la dette",
    "app_feature_48": "Anciennet√© du cr√©dit bureau",
    "app_feature_49": "Ratio cr√©dit/revenu",
    
    # Variables des autres sources de donn√©es
    "bureau_feat_0": "Cr√©dits Bureau",
    "bureau_feat_1": "Dur√©e des cr√©dits Bureau",
    "bureau_feat_2": "Anciennet√© des cr√©dits Bureau",
    "bureau_feat_3": "Dettes Bureau",
    "bureau_feat_4": "Cr√©dits en cours Bureau",
    "prev_app_feat_0": "Anciennet√© demandes pr√©c√©dentes",
    "prev_app_feat_1": "Taux d'acceptation demandes pr√©c√©dentes",
    "prev_app_feat_2": "Montant moyen demandes pr√©c√©dentes",
    "prev_app_feat_3": "Dur√©e moyenne demandes pr√©c√©dentes",
    "prev_app_feat_4": "Ratio de remboursement demandes pr√©c√©dentes",
    "pos_feat_0": "Anciennet√© POS Cash",
    "pos_feat_1": "Nb de paiements POS Cash",
    "pos_feat_2": "Montant POS Cash",
    "pos_feat_3": "Jours de retard POS Cash",
    "pos_feat_4": "Statut de paiement POS Cash",
    "install_feat_0": "Anciennet√© Paiements acomptes",
    "install_feat_1": "Nb de paiements acomptes",
    "install_feat_2": "Montant paiements acomptes",
    "install_feat_3": "Paiements en retard acomptes",
    "install_feat_4": "Ratio paiement/facture acomptes",
    "cc_feat_0": "Anciennet√© Carte de Cr√©dit",
    "cc_feat_1": "Nb de transactions Carte de Cr√©dit",
    "cc_feat_2": "Montant solde Carte de Cr√©dit",
    "cc_feat_3": "Utilisation de la limite Carte de Cr√©dit",
    "cc_feat_4": "Paiements en retard Carte de Cr√©dit",
    
    # Mapping pour les variables cat√©gorielles
    "NAME_CONTRACT_TYPE": "Type de Contrat",
    "CODE_GENDER": "Sexe",
    "FLAG_OWN_CAR": "Poss√®de une Voiture",
    "NAME_INCOME_TYPE": "Type de Revenu",
}
# Cette ligne est d√©j√† d√©finie, pas besoin de la r√©p√©ter
# SHAP_IMPORTANT_FEATURES_NAMES = list(SHAP_IMPORTANT_FEATURES_INFO.keys())

# --- Fonctions Stub pour la G√©n√©ration de Donn√©es (utilis√©es pour la d√©mo) ---
@st.cache_data(show_spinner="Chargement des donn√©es...")
def load_application_data_stub(num_rows):
    """
    Charge et retourne les donn√©es.
    Cette fonction ne s'ex√©cutera qu'une seule fois.
    """
    try:
        # --- MODIFICATION ICI ---
        # Remplacez 'REMPLACEZ_PAR_VOTRE_FICHIER_CSV.csv' par le nom r√©el de votre fichier CSV
        # Par exemple: 'input/application_train.csv'
        df = pd.read_csv('input/application_train.csv') # Remplacez 'application_train.csv' par le nom de votre fichier 
        return df
    except FileNotFoundError:
        st.error("Fichier de donn√©es non trouv√©. Assurez-vous que le fichier est bien √† sa place dans le dossier 'input'.")
        return None

@st.cache_data(show_spinner="Traitement des donn√©es Bureau...")
def process_bureau_data_stub(df):
    for i in range(5):
        if f'bureau_feat_{i}' not in df.columns:
            df[f'bureau_feat_{i}'] = np.random.rand(len(df))
    return df

@st.cache_data(show_spinner="Traitement des demandes pr√©c√©dentes...")
def process_previous_applications_data_stub(df):
    for i in range(5):
        if f'prev_app_feat_{i}' not in df.columns:
            df[f'prev_app_feat_{i}'] = np.random.rand(len(df))
    return df

@st.cache_data(show_spinner="Traitement des donn√©es POS Cash...")
def process_pos_cash_data_stub(df):
    for i in range(5):
        if f'pos_feat_{i}' not in df.columns:
            df[f'pos_feat_{i}'] = np.random.rand(len(df))
    return df

@st.cache_data(show_spinner="Traitement des paiements d'acomptes...")
def process_installments_payments_data_stub(df):
    for i in range(5):
        if f'install_feat_{i}' not in df.columns:
            df[f'install_feat_{i}'] = np.random.rand(len(df))
    return df

@st.cache_data(show_spinner="Traitement des donn√©es de carte de cr√©dit...")
def process_credit_card_balance_data_stub(df):
    for i in range(5):
        if f'cc_feat_{i}' not in df.columns:
            df[f'cc_feat_{i}'] = np.random.rand(len(df))
    return df

@st.cache_data(show_spinner="Ex√©cution du pipeline d'ing√©nierie des caract√©ristiques...")
def run_feature_engineering_pipeline(num_rows):
    df = load_application_data_stub(num_rows)
    df = process_bureau_data_stub(df)
    df = process_previous_applications_data_stub(df)
    df = process_pos_cash_data_stub(df)
    df = process_installments_payments_data_stub(df)
    df = process_credit_card_balance_data_stub(df)
    return df

# --- 5. Loading Functions (Cached) ---
# Cette fonction est modifi√©e pour charger les m√©tadonn√©es en dur
# car nous ne nous connectons plus √† un serveur MLflow distant.
@st.cache_resource(show_spinner="Chargement des m√©tadonn√©es du mod√®le...")
def load_model_metadata_local():
    # Utilisation des dictionnaires d√©finis directement dans le script
    features_info = SHAP_IMPORTANT_FEATURES_INFO
    optimal_threshold = 0.5 # Valeur par d√©faut, ajustez si n√©cessaire
    
    # G√©n√©ration des noms de colonnes via le stub pour simuler les features d'entra√Ænement
    dummy_data = run_feature_engineering_pipeline(num_rows=1)
    all_training_features = list(dummy_data.columns)
    
    logger.info("M√©tadonn√©es du mod√®le charg√©es localement.")
    return features_info, optimal_threshold, all_training_features

@st.cache_resource(show_spinner="Chargement du pipeline du mod√®le...")
def load_mlflow_pipeline_local():
    """
    Charge le pipeline MLflow depuis le chemin local sp√©cifi√©.
    """
    try:
        pipeline = mlflow.pyfunc.load_model(model_uri=LOCAL_MODEL_PATH)
        logger.info(f"Streamlit: Pipeline charg√© depuis '{LOCAL_MODEL_PATH}'.")
        return pipeline
    except Exception as e:
        st.error(f"√âchec lors du chargement du pipeline local: {e}")
        st.info(f"Assurez-vous que le dossier '{LOCAL_MODEL_PATH}' existe et contient un mod√®le MLflow valide.")
        return None

@st.cache_resource(show_spinner="Calcul de l'explainer SHAP...")
def load_shap_explainer(_pipeline, all_training_features):
    # Assurez-vous que le pipeline a bien un 'preprocessor'
    if 'preprocessor' in _pipeline.named_steps:
        preprocessor = _pipeline.named_steps['preprocessor']
    else:
        # Si le pipeline n'a pas de pr√©processeur nomm√© 'preprocessor',
        # cela signifie que le mod√®le est peut-√™tre directement le classifieur
        # ou que le pr√©processeur est int√©gr√© diff√©remment.
        # Pour cet exemple, nous allons simuler un pr√©processeur si absent.
        logger.warning("Le pipeline ne contient pas de 'preprocessor' nomm√©. SHAP pourrait n√©cessiter un ajustement.")
        # Utiliser une identit√© si pas de pr√©processeur explicite
        class IdentityPreprocessor:
            def transform(self, X):
                return X
            def get_feature_names_out(self):
                return X.columns
        preprocessor = IdentityPreprocessor()
    
    final_model = _pipeline.steps[-1][1] # Le dernier pas du pipeline est le mod√®le final
    
    # G√©n√©ration de donn√©es de r√©f√©rence pour l'explainer SHAP
    # Assurez-vous que ces donn√©es sont repr√©sentatives de vos donn√©es d'entra√Ænement
    ref_data_raw = run_feature_engineering_pipeline(num_rows=1000)
    
    # Assurez-vous que les colonnes de ref_data_raw correspondent √† all_training_features
    # avant de les passer au pr√©processeur
    ref_data_raw_filtered = ref_data_raw[all_training_features]
    
    ref_data_processed = preprocessor.transform(ref_data_raw_filtered)
    
    # Obtenir les noms de features apr√®s pr√©processing
    # Si preprocessor.get_feature_names_out() n'existe pas ou ne fonctionne pas,
    # vous devrez peut-√™tre les d√©duire manuellement ou les d√©finir.
    try:
        processed_feature_names = preprocessor.get_feature_names_out()
    except AttributeError:
        # Fallback si get_feature_names_out n'est pas disponible
        processed_feature_names = [f"col_{i}" for i in range(ref_data_processed.shape[1])]
        logger.warning("Impossible d'obtenir les noms de features du pr√©processeur. Noms g√©n√©riques utilis√©s.")

    ref_data_df = pd.DataFrame(ref_data_processed, columns=processed_feature_names)
    
    return shap.Explainer(final_model, ref_data_df)

@st.cache_data(show_spinner="G√©n√©ration des donn√©es de r√©f√©rence pour le drift...")
def load_reference_data_for_drift():
    try:
        # Utilise la fonction stub pour g√©n√©rer des donn√©es de r√©f√©rence
        reference_df = run_feature_engineering_pipeline(num_rows=30000)
        logger.info(f"Donn√©es de r√©f√©rence charg√©es avec succ√®s. Nombre d'√©chantillons: {len(reference_df)}")
        return reference_df
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es de r√©f√©rence : {e}")
        st.stop()
        return None

# --- Fonctions d'Affichage des Rapports ---
def generate_and_display_evidently_report(reference_df, current_df):
    try:
        st.info("G√©n√©ration du rapport en cours. Cela peut prendre quelques instants...")
        report_file_path = "evidently_data_drift_report_temp.html"
        data_drift_dashboard = Dashboard(tabs=[DataDriftTab()])
        data_drift_dashboard.calculate(reference_data=reference_df, current_data=current_df)
        data_drift_dashboard.save(report_file_path)
        with open(report_file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        components.html(html_content, height=1000, scrolling=True)
        st.success("Rapport Evidently g√©n√©r√© et affich√© avec succ√®s.")
        os.remove(report_file_path)
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration ou de l'affichage du rapport Evidently : {e}")
        logger.exception("Erreur lors de l'ex√©cution du rapport Evidently dans Streamlit:")

def map_feature_names(processed_feature_names, name_mapping):
    """
    Remplace les noms de colonnes transform√©s par des noms lisibles en utilisant
    un dictionnaire de mapping plus complet.
    """
    readable_names = []
    for name in processed_feature_names:
        # Nettoyer les pr√©fixes du pr√©processeur
        base_name = name.split('__')[-1]
        
        # 1. Chercher une correspondance exacte dans le dictionnaire complet
        if base_name in name_mapping:
            readable_name = name_mapping[base_name]
        # 2. Chercher une correspondance pour les variables cat√©gorielles (ex: NAME_CONTRACT_TYPE_Cash)
        elif '_' in base_name:
            parts = base_name.split('_')
            original_name = '_'.join(parts[:-1]) # Variable d'origine (ex: NAME_CONTRACT_TYPE)
            category = parts[-1] # Cat√©gorie (ex: Cash)
            if original_name in name_mapping:
                readable_name = f"{name_mapping[original_name]} : {category}"
            else:
                readable_name = base_name
        # 3. Utiliser le nom brut s'il n'y a pas de correspondance
        else:
            readable_name = base_name
            
        readable_names.append(readable_name)
    return readable_names

# Fonction utilitaire pour afficher les plots SHAP
def st_shap(plot, height=None):
    shap_html = f"<head>{shap.getjs()}</head><body>{plot.html()}</body>"
    components.html(shap_html, height=height)

def display_shap_plot(shap_explainer, input_df, all_training_features, preprocessor):
    """G√©n√®re et affiche le force plot SHAP pour une seule pr√©diction."""
    st.subheader("üìä Explication de la Pr√©diction (SHAP)")
    st.info("""
        Le graphique SHAP ci-dessous montre comment chaque caract√©ristique a contribu√© √† la pr√©diction.
        -   **Les valeurs rouges** poussent la pr√©diction vers un risque √©lev√©.
        -   **Les valeurs bleues** poussent la pr√©diction vers un risque faible.
        -   **f(x)** est la probabilit√© pr√©dite par le mod√®le.
        -   **E[f(x)]** est la probabilit√© moyenne du mod√®le sur l'ensemble de l'entra√Ænement.
    """)
    try:
        # Assurez-vous que input_df contient toutes les colonnes attendues par le pr√©processeur
        # et dans le bon ordre.
        # Si input_df n'a que les features importantes, il faut le compl√©ter avec des z√©ros
        # ou des valeurs par d√©faut pour les autres features attendues par le pr√©processeur.
        
        # Pour la d√©mo, on s'assure que input_df a toutes les colonnes de all_training_features
        # avec des valeurs par d√©faut si elles ne sont pas dans user_inputs
        full_input_df = pd.DataFrame(columns=all_training_features)
        full_input_df.loc[0] = 0 # Initialise avec des z√©ros
        for col in input_df.columns:
            if col in full_input_df.columns:
                full_input_df[col] = input_df[col]

        input_for_shap = preprocessor.transform(full_input_df[all_training_features])
        shap_values_instance = shap_explainer(input_for_shap)
        
        processed_feature_names = preprocessor.get_feature_names_out()
        readable_feature_names = map_feature_names(processed_feature_names, FULL_DESCRIPTIVE_NAMES)
        
        # Assurez-vous que les noms de features sont correctement mapp√©s pour l'affichage SHAP
        processed_features_series = pd.Series(shap_values_instance.data[0], index=readable_feature_names)
        
        fig = shap.force_plot(
            base_value=shap_explainer.expected_value[0] if isinstance(shap_explainer.expected_value, np.ndarray) else shap_explainer.expected_value,
            shap_values=shap_values_instance.values[0],
            features=processed_features_series,
            matplotlib=False
        )
        st_shap(fig, height=250)
    except Exception as e:
        st.error(f"Erreur lors de la g√©n√©ration du graphique SHAP : {e}")
        logger.exception("Erreur lors de l'ex√©cution de SHAP dans Streamlit:")

# --- 6. Chargement des Ressources au D√©marrage ---
# Utilisation des fonctions de chargement local
features_info, optimal_threshold, all_training_features = load_model_metadata_local()
pipeline = load_mlflow_pipeline_local()

# --- 7. Contenu Principal de la Page Streamlit ---
st.title("üìä Pr√©diction de D√©faut Client & Surveillance du Mod√®le")

tab1, tab2 = st.tabs(["Pr√©diction de Pr√™t", "Analyse du Data Drift"])

with tab1:
    st.markdown("""
    Cette application vous permet de simuler une pr√©diction de risque de d√©faut pour un client.
    """)
    if features_info and pipeline: # V√©rifie que le mod√®le et les m√©tadonn√©es sont charg√©s
        st.sidebar.header("Informations sur le Mod√®le")
        st.sidebar.write(f"**Nom du Mod√®le :** `Pipeline de R√©gression Logistique`") # Nom g√©n√©rique
        st.sidebar.write(f"**Source du Mod√®le :** `Local (Dossier '{LOCAL_MODEL_PATH}')`")
        st.sidebar.write(f"**Seuil Optimal Utilis√© :** `{optimal_threshold:.4f}`")
        st.sidebar.write(f"**Nombre de Caract√©ristiques Importantes :** `{len(features_info)}`")

        st.subheader("Saisie des Caract√©ristiques Client Importantes")
        user_inputs = {}
        num_columns = 2
        cols = st.columns(num_columns)
        
        for i, (feature_original_name, info) in enumerate(features_info.items()):
            display_name = info.get("display_name", feature_original_name)
            min_val_hint = info.get("min_val")
            max_val_hint = info.get("max_val")
            default_value = (float(min_val_hint) + float(max_val_hint)) / 2 if min_val_hint is not None and max_val_hint is not None else 0.0
            with cols[i % num_columns]:
                st.write(f"**{display_name}**")
                st.caption(f"Plage: [{min_val_hint:.2f} - {max_val_hint:.2f}]" if min_val_hint is not None and max_val_hint is not None else "Plage: N/A")
                user_inputs[feature_original_name] = st.number_input(
                    label=" ",
                    value=float(default_value),
                    min_value=float(min_val_hint) if min_val_hint is not None else None,
                    max_value=float(max_val_hint) if max_val_hint is not None else None,
                    format="%.4f",
                    key=f"input_{feature_original_name}"
                )
        st.markdown("---")
        if st.button("Obtenir la Pr√©diction", help="Cliquez pour ex√©cuter le mod√®le avec les valeurs saisies."):
            # Cr√©er un DataFrame avec toutes les colonnes attendues par le mod√®le
            # en utilisant les valeurs par d√©faut (0.0) pour les features non saisies
            model_input_data = {
                feature_name: user_inputs.get(feature_name, 0.0)
                for feature_name in all_training_features
            }
            input_df = pd.DataFrame([model_input_data])
            
            try:
                # Charger l'explainer SHAP et le pr√©processeur
                shap_explainer = load_shap_explainer(pipeline, all_training_features)
                preprocessor_for_shap = pipeline.named_steps['preprocessor']
                
                prediction_proba = pipeline.predict_proba(input_df)[:, 1][0]
                prediction_class = 1 if prediction_proba >= optimal_threshold else 0
                st.subheader("üéâ R√©sultat de la Pr√©diction :")
                col_proba, col_class = st.columns(2)
                with col_proba:
                    st.metric(label="Probabilit√© de D√©faut", value=f"{prediction_proba:.4f}")
                with col_class:
                    if prediction_class == 1:
                        st.error("‚ö†Ô∏è **Client √† Risque de D√©faut √âlev√©**")
                    else:
                        st.success("‚úÖ **Client √† Risque de D√©faut Faible**")
                
                display_shap_plot(shap_explainer, input_df, all_training_features, preprocessor_for_shap)
                
            except Exception as e:
                st.error(f"Une erreur est survenue lors de l'ex√©cution de la pr√©diction : {e}")
                logger.exception("Erreur lors de la pr√©diction Streamlit:")
    else:
        st.error("L'application n'a pas pu √™tre initialis√©e. V√©rifiez les logs pour plus de d√©tails.")

with tab2:
    st.header("Analyse du Data Drift (Evidently AI)")
    st.markdown("""
    Cette section g√©n√®re et affiche un rapport de **Data Drift** directement dans l'application.
    Le rapport compare les donn√©es d'entra√Ænement (r√©f√©rence) aux donn√©es de production simul√©es.
    """)
    
    if st.button("G√©n√©rer et afficher le rapport de Data Drift"):
        reference_data_for_drift = load_reference_data_for_drift()
        
        # Simulation de data drift
        df_production = reference_data_for_drift.copy()
        if 'AMT_CREDIT' in df_production.columns:
            df_production['AMT_CREDIT'] = df_production['AMT_CREDIT'] * np.random.normal(1.2, 0.1, len(df_production))
        if 'app_feature_17' in df_production.columns: # Correspond √† l'√¢ge client
            df_production['app_feature_17'] = df_production['app_feature_17'] + np.random.randint(-5, 5, len(df_production))
        
        generate_and_display_evidently_report(reference_data_for_drift, df_production)
    else:
        st.warning("Cliquez sur le bouton pour g√©n√©rer le rapport de d√©rive des donn√©es.")
