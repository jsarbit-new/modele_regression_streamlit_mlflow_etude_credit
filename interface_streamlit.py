import streamlit as st
import pandas as pd
import numpy as np
import mlflow
import json
import logging

# --- 1. Configuration de la Page Streamlit (DOIT ABSOLUMENT √äTRE LA PREMI√àRE COMMANDE ST.) ---
st.set_page_config(
    page_title="Pr√©diction de D√©faut Client",
    page_icon="üìä",
    layout="wide" # Utilise la largeur maximale disponible de la page
)

# --- 2. Configuration du Logging pour Streamlit ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- 3. Configuration MLflow pour l'Application ---
MLFLOW_TRACKING_URI = "http://127.0.0.1:5000" # L'adresse de votre serveur MLflow UI
MLFLOW_MODEL_NAME = "HomeCreditLogisticRegressionPipeline" # Doit correspondre au nom enregistr√© dans le script d'entra√Ænement

try:
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    logger.info(f"Streamlit: MLflow tracking URI set to: {MLFLOW_TRACKING_URI}")
except Exception as e:
    st.error(f"Streamlit: Erreur critique lors de la configuration de MLflow Tracking URI: {e}")
    st.info("V√©rifiez que votre serveur MLflow est d√©marr√© et accessible √† l'adresse sp√©cifi√©e.")
    st.stop() # Arr√™te l'application si MLflow n'est pas joignable

# --- 4. Fonction de Chargement du Mod√®le et des M√©tadonn√©es (Mise en Cache) ---
@st.cache_resource(show_spinner="Chargement du mod√®le de pr√©diction et de ses m√©tadonn√©es depuis MLflow...")
def load_mlflow_model_and_metadata():
    """
    Charge le mod√®le et ses m√©tadonn√©es (features_info, seuil optimal, all_training_features)
    depuis MLflow Model Registry. Cette fonction est mise en cache pour n'√™tre ex√©cut√©e qu'une seule fois.
    """
    try:
        client = mlflow.tracking.MlflowClient()

        # R√©cup√©rer toutes les versions du mod√®le, puis trouver la plus r√©cente en Python
        model_versions = client.search_model_versions(f"name='{MLFLOW_MODEL_NAME}'")
        
        if not model_versions:
            error_msg = (f"Aucune version du mod√®le '{MLFLOW_MODEL_NAME}' trouv√©e dans le Model Registry MLflow. "
                         "Assurez-vous que le script d'entra√Ænement a √©t√© ex√©cut√© et que le mod√®le "
                         "a √©t√© enregistr√© avec le nom sp√©cifi√©.")
            logger.error(f"Streamlit: {error_msg}")
            raise ValueError(error_msg)

        # Trier les versions par num√©ro de version dans l'ordre d√©croissant pour obtenir la derni√®re
        latest_version = max(model_versions, key=lambda mv: mv.version)
        
        model_uri = f"models:/{MLFLOW_MODEL_NAME}/{latest_version.version}"
        
        # --- C'EST LA LIGNE MODIFI√âE POUR CHARGER LE MOD√àLE SCALAR ---
        # Utiliser mlflow.sklearn.load_model pour charger le mod√®le avec son "flavor" Scikit-learn
        model = mlflow.sklearn.load_model(model_uri=model_uri) 
        # La ligne pr√©c√©dente √©tait: model = mlflow.pyfunc.load_model(model_uri)

        logger.info(f"Streamlit: Mod√®le '{MLFLOW_MODEL_NAME}' (Version {latest_version.version}) charg√© avec succ√®s en tant que Scikit-learn model.")

        features_info = None
        optimal_threshold = None
        all_training_features = None

        # R√©cup√©rer les m√©tadonn√©es des tags du mod√®le (Priorit√© 1: source la plus fiable)
        model_metadata_tags = latest_version.tags if hasattr(latest_version, 'tags') else {}
        
        optimal_threshold_str = model_metadata_tags.get('mlflow.log_model.metadata.optimal_threshold')
        features_info_str = model_metadata_tags.get('mlflow.log_model.metadata.features_info_for_streamlit')
        all_training_features_str = model_metadata_tags.get('mlflow.log_model.metadata.all_training_features')

        if optimal_threshold_str:
            optimal_threshold = float(optimal_threshold_str)
            logger.info(f"Streamlit: Seuil optimal r√©cup√©r√© des tags du mod√®le: {optimal_threshold:.4f}")
        else:
            logger.warning("Streamlit: Seuil optimal non trouv√© dans les tags du mod√®le. Tentative de fallback...")

        if features_info_str:
            features_info = json.loads(features_info_str)
            logger.info(f"Streamlit: Informations sur les features r√©cup√©r√©es des tags du mod√®le ({len(features_info)} features).")
        else:
            logger.warning("Streamlit: Informations sur les features non trouv√©es dans les tags du mod√®le. Tentative de fallback...")

        if all_training_features_str:
            all_training_features = json.loads(all_training_features_str)
            logger.info(f"Streamlit: Liste compl√®te des features d'entra√Ænement r√©cup√©r√©e des tags du mod√®le ({len(all_training_features)} features).")
        else:
            logger.warning("Streamlit: Liste compl√®te des features d'entra√Ænement non trouv√©e dans les tags du mod√®le. Tentative de fallback...")

        # Fallback pour r√©cup√©rer des param√®tres de la run si les tags du mod√®le sont absents (Priorit√© 2)
        # Ceci est utile si le mod√®le a √©t√© logg√© avec une version de MLflow qui ne met pas
        # automatiquement les metadata dans les tags du mod√®le, ou si les tags n'√©taient pas pass√©s au metadata param.
        if features_info is None or optimal_threshold is None or all_training_features is None:
            logger.warning("Streamlit: Tentative de r√©cup√©ration des m√©tadonn√©es manquantes depuis les param√®tres de la run MLflow...")
            run_info = client.get_run(latest_version.run_id)
            run_info_params = run_info.data.params
            
            if optimal_threshold is None and 'optimal_threshold_value' in run_info_params:
                optimal_threshold = float(run_info_params['optimal_threshold_value'])
                logger.info(f"Streamlit: Seuil optimal r√©cup√©r√© des param√®tres de la run: {optimal_threshold:.4f}")
            
            if features_info is None and 'features_info_for_streamlit_json' in run_info_params:
                features_info_json = run_info_params['features_info_for_streamlit_json']
                features_info = json.loads(features_info_json)
                logger.info(f"Streamlit: Informations sur les features r√©cup√©r√©es des param√®tres de la run ({len(features_info)} features).")
            
            if all_training_features is None and 'all_training_features_names' in run_info_params:
                all_training_features_json = run_info_params['all_training_features_names']
                all_training_features = json.loads(all_training_features_json)
                logger.info(f"Streamlit: Liste compl√®te des features d'entra√Ænement r√©cup√©r√©e des param√®tres de la run ({len(all_training_features)} features).")

        # V√©rifications finales apr√®s toutes les tentatives de r√©cup√©ration
        if features_info is None or not features_info: 
            raise ValueError("Impossible de d√©terminer la liste des variables d'entr√©e importantes pour l'interface. "
                             "Veuillez vous assurer qu'elles sont loggu√©es correctement lors de l'entra√Ænement.")
        
        if optimal_threshold is None:
            optimal_threshold = 0.5 # Seuil par d√©faut si vraiment rien n'est trouv√©
            logger.warning(f"Streamlit: Seuil optimal non trouv√© du tout. Utilisation d'un seuil par d√©faut de {optimal_threshold}.")
        
        if all_training_features is None or not all_training_features:
            # Si all_training_features n'est pas trouv√©, le mod√®le pyfunc pourrait avoir du mal.
            # Comme fallback, on peut essayer de le d√©duire des cl√©s de features_info, mais ce n'est pas l'id√©al
            logger.warning("Liste compl√®te des features d'entra√Ænement ('all_training_features') non trouv√©e. "
                           "Cela pourrait causer des probl√®mes si les features d'entr√©e ne sont pas ordonn√©es comme pr√©vu.")
            all_training_features = list(features_info.keys()) # Fallback minimal

        return model, features_info, optimal_threshold, all_training_features

    except Exception as e:
        st.error(f"Streamlit: √âchec critique lors du chargement du mod√®le ou de ses m√©tadonn√©es: {e}")
        st.info("""
            **V√©rifiez les points suivants pour r√©soudre le probl√®me :**
            1.  **Serveur MLflow UI d√©marr√© :** Assurez-vous que `mlflow ui` (avec le bon `--backend-store-uri` si n√©cessaire) est bien en cours d'ex√©cution dans un terminal s√©par√©.
            2.  **Mod√®le enregistr√© :** V√©rifiez que le mod√®le nomm√© `HomeCreditLogisticRegressionPipeline` est visible dans l'onglet "Models" de l'interface MLflow UI et qu'il a des **tags/m√©tadonn√©es** pour 'optimal_threshold' et 'features_info_for_streamlit'.
            3.  **Logs d'entra√Ænement :** Examinez les logs de votre script d'entra√Ænement pour confirmer que le mod√®le a √©t√© enregistr√© sans erreur et que la liste des features et le seuil optimal ont √©t√© loggu√©s correctement.
        """)
        st.stop()
        return None, None, None, None

# --- 5. Chargement des Ressources au D√©marrage de l'Application Streamlit ---
# Ces variables contiendront le mod√®le et ses m√©tadonn√©es une fois charg√©es
model, features_info, optimal_threshold, all_training_features = load_mlflow_model_and_metadata()

# --- 6. Contenu Principal de la Page Streamlit ---
st.title("üìä Pr√©diction de D√©faut Client (Mod√®le de R√©gression Logistique)")
st.markdown("""
Cette application interactive vous permet de simuler une pr√©diction de risque de d√©faut pour un client.
Entrez les valeurs des caract√©ristiques ci-dessous et le mod√®le calculera la probabilit√© de d√©faut,
puis classifiera le client comme √† "Risque √âlev√©" ou "Risque Faible" en utilisant le seuil optimal d√©termin√© lors de l'entra√Ænement.
""")

# Affichage des informations sur le mod√®le charg√© dans une barre lat√©rale pour le d√©bogage et l'information
if model and features_info:
    st.sidebar.header("Informations sur le Mod√®le")
    st.sidebar.write(f"**Nom du Mod√®le :** `{MLFLOW_MODEL_NAME}`")
    try:
        current_version_obj = mlflow.tracking.MlflowClient().get_latest_versions(MLFLOW_MODEL_NAME, stages=['None', 'Production', 'Staging'])
        current_version = current_version_obj[0].version if current_version_obj else "N/A"
        st.sidebar.write(f"**Version du Mod√®le :** `{current_version}`")
    except Exception as e:
        st.sidebar.warning(f"Impossible de r√©cup√©rer la version du mod√®le: {e}")
    st.sidebar.write(f"**Seuil Optimal Utilis√© :** `{optimal_threshold:.4f}`")
    st.sidebar.write(f"**Nombre de Caract√©ristiques Importantes :** `{len(features_info)}`")
    st.sidebar.info("V√©rifiez les logs de votre terminal pour plus de d√©tails sur le chargement.")

# --- 7. Interface de Saisie des Caract√©ristiques ---
if model is not None and features_info is not None and all_training_features is not None:
    st.subheader("Saisie des Caract√©ristiques Client Importantes")
    st.markdown("Veuillez remplir les champs ci-dessous. Les valeurs par d√©faut sont celles du dataset (ou 0.0 si non sp√©cifi√©). "
                "Vous pouvez les modifier pour voir l'impact sur la pr√©diction. "
                "Les plages de valeurs sont indicatives, bas√©es sur l'entra√Ænement.")

    user_inputs = {}
    num_columns = 2 # Afficher les champs de saisie en 2 colonnes pour les features importantes
    cols = st.columns(num_columns)
    col_idx = 0

    # It√©rer sur le dictionnaire features_info pour cr√©er les champs de saisie
    for feature_original_name, info in features_info.items():
        display_name = info.get("display_name", feature_original_name)
        min_val_hint = info.get("min_val")
        max_val_hint = info.get("max_val")
        
        # Valeur par d√©faut : milieu de la plage ou 0.0 si non d√©fini. Convertir en float.
        default_value = (float(min_val_hint) + float(max_val_hint)) / 2 if min_val_hint is not None and max_val_hint is not None else 0.0

        with cols[col_idx]:
            st.write(f"**{display_name}**")
            st.caption(f"Plage: [{min_val_hint:.2f} - {max_val_hint:.2f}]" if min_val_hint is not None and max_val_hint is not None else "Plage: N/A")
            
            user_inputs[feature_original_name] = st.number_input(
                label=" ", # Label vide car le nom est d√©j√† au-dessus
                value=float(default_value), 
                min_value=float(min_val_hint) if min_val_hint is not None else None,
                max_value=float(max_val_hint) if max_val_hint is not None else None,
                format="%.4f", # Formate l'affichage du nombre avec 4 d√©cimales
                key=f"input_{feature_original_name}" # Cl√© unique pour chaque widget Streamlit
            )
        col_idx = (col_idx + 1) % num_columns

    st.markdown("---")

    # --- 8. Bouton de Pr√©diction et Affichage des R√©sultats ---
    if st.button("Obtenir la Pr√©diction", help="Cliquez pour ex√©cuter le mod√®le avec les valeurs saisies."):
        # Cr√©er un DataFrame d'entr√©e pour le mod√®le avec TOUTES les features attendues par le pipeline.
        # Les features non affich√©es dans l'interface Streamlit seront remplies avec une valeur par d√©faut.
        
        model_input_data = {}
        for feature_name in all_training_features:
            if feature_name in user_inputs:
                model_input_data[feature_name] = user_inputs[feature_name]
            else:
                # Valeur par d√©faut pour les features non saisies (souvent 0 pour les num√©riques).
                # Le pr√©processeur du pipeline g√©rera l'imputation et la mise √† l'√©chelle.
                # Pour des features cat√©gorielles non importantes, il faudrait une logique plus complexe (ex: mode, 'Unknown').
                model_input_data[feature_name] = 0.0 

        input_df = pd.DataFrame([model_input_data])
        
        # Assurez-vous que l'ordre des colonnes correspond √† l'ordre attendu par le mod√®le.
        # C'est crucial pour les mod√®les qui n'ont pas une signature d'entr√©e stricte ou des pr√©processeurs sensibles √† l'ordre.
        input_df = input_df[all_training_features] 

        try:
            # predict_proba renvoie un tableau numpy, [:, 1] pour la probabilit√© de la classe positive
            prediction_proba = model.predict_proba(input_df)[:, 1][0] # [0] pour obtenir la valeur unique de la probabilit√©

            prediction_class = 1 if prediction_proba >= optimal_threshold else 0

            st.subheader("üéâ R√©sultat de la Pr√©diction :")

            col_proba, col_class = st.columns(2)
            with col_proba:
                st.metric(label="Probabilit√© de D√©faut", value=f"{prediction_proba:.4f}")

            with col_class:
                if prediction_class == 1:
                    st.error("‚ö†Ô∏è **Client √† Risque de D√©faut √âlev√©**")
                else:
                    st.success("‚úÖ **Client √† Risque de D√©faut Faible**")

            st.markdown("---")
            st.write(f"**D√©tails de l'analyse :**")
            st.markdown(f"- Le mod√®le a calcul√© une probabilit√© de d√©faut de **`{prediction_proba:.4f}`**.")
            st.markdown(f"- Le **seuil de classification utilis√© est de `{optimal_threshold:.4f}`**. Ce seuil a √©t√© sp√©cifiquement optimis√© lors de l'entra√Ænement pour maximiser la m√©trique F-beta.")
            st.markdown(f"- Si la probabilit√© calcul√©e (`{prediction_proba:.4f}`) est sup√©rieure ou √©gale au seuil (`{optimal_threshold:.4f}`), le client est class√© comme 'Risque √âlev√©'.")

        except Exception as e:
            st.error(f"Une erreur est survenue lors de l'ex√©cution de la pr√©diction : {e}")
            st.warning("V√©rifiez que toutes les valeurs saisies sont num√©riques et coh√©rentes avec les attentes du mod√®le.")
            logger.exception("Erreur lors de la pr√©diction Streamlit:") # Log l'exception compl√®te pour le d√©bogage

else:
    st.error("L'application n'a pas pu √™tre initialis√©e car le mod√®le ou ses m√©tadonn√©es n'ont pas √©t√© charg√©s. Veuillez r√©soudre les erreurs signal√©es ci-dessus et relancer l'application.")